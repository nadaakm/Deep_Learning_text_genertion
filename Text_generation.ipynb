{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We are going to train a model to generate shakespearian text using a simple Recurrent Neural Network"
      ],
      "metadata": {
        "id": "H6KaDCHnX6hZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwPj0SzJITPi"
      },
      "outputs": [],
      "source": [
        "#Phase 1 : Imports\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "id": "Hpurhc8NYDLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e83043-971d-4302-9426-130b4a7cb97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "1130496/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(path_to_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6v_2gTqYGZQ",
        "outputId": "e4e7e4bb-d777-47b6-e212-7065f0be188c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets/shakespeare.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print(text[0:250])\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FwLP1uwYH0T",
        "outputId": "67d640ff-8190-4c5e-eec7-7ea5f6a923cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text.split('\\n')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAC5u-cpS9US",
        "outputId": "d5932b05-6065-4f0c-ea02-1eec380b0789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYHebNYZYL3r",
        "outputId": "c1b67c99-ad9b-4f2a-eaff-0ae483ddfb32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n",
        "\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "QZUXadlgYXq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First task : we need to divide our corpus into examples\n",
        "\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBYsi9TlYmK0",
        "outputId": "326d5b54-fb66-4230-edbe-19a6393ec5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "ids_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uoTCS79YoNb",
        "outputId": "68fad171-2b7c-486f-eafa-446bd4a55322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print('{} : {}'.format(ids,chars_from_ids(ids).numpy().decode('utf-8')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miKR5j5TZRjf",
        "outputId": "2f0c9a5e-4046-4f40-a5a3-d2c8afdf1291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 : F\n",
            "48 : i\n",
            "57 : r\n",
            "58 : s\n",
            "59 : t\n",
            "2 :  \n",
            "16 : C\n",
            "48 : i\n",
            "59 : t\n",
            "48 : i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Nous allons donc partager notre text en exemples de 100 caractéres;\n",
        "#Chaque exemple aura son x qui représente 100 charactéres, et y qui représente les 100 prochains caractéres après\n",
        "#Le premier charactére de x.\n",
        "#Exemple : texte original : \"Bonjour, je m'appelle groot\", x = Bonjour, je m'appelle g, y = onjour, je m'appelle gr\n",
        "seq_length = 100\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBMpvYQxZVaZ",
        "outputId": "78853c70-05d1-47c3-f762-b9a225e814ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n",
            "now Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us ki\n",
            "ll him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be d\n",
            "one: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#On va générer à partir de chaque exemple un input (x) et un label (y), en sachat que y représente le prochain caractére après x\n",
        "#exemple\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL5Z1S0EaGUP",
        "outputId": "de9d5b2e-3668-4cef-ec3f-880a4931b8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Notre corpus a été traité et maintenant nous avons un dataset\n",
        "#avec l'input et le label correspondant.\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "Hnow0OccbYUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(5):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy().decode('utf-8'))\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy().decode('utf-8'))\n",
        "    print('--------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLG99R9BbkHW",
        "outputId": "8aa11b0b-8860-453a-8154-55401c70fab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "Target: irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "--------------------------------------------------------------\n",
            "Input : are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "Target: re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n",
            "--------------------------------------------------------------\n",
            "Input : now Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us k\n",
            "Target: ow Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us ki\n",
            "--------------------------------------------------------------\n",
            "Input : ll him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be \n",
            "Target: l him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be d\n",
            "--------------------------------------------------------------\n",
            "Input : one: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor cit\n",
            "Target: ne: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citi\n",
            "--------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(32).batch(32,drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "T4-5amh7bmKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "BqUHE4d6cIt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukupnJMEhAWA",
        "outputId": "da8f941d-6f12-49b5-a31d-543fc19011eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class text_generator(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x\n",
        "\n",
        "model = text_generator(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "vp-Id9r1z-6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "    print(example_batch_predictions[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3AiRLgrgEXJ",
        "outputId": "98ef37f2-356f-442f-cec8-abba27aae989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 100, 66) # (batch_size, sequence_length, vocab_size)\n",
            "tf.Tensor(\n",
            "[[ 0.01037958  0.00218541 -0.0099556  ... -0.00103169 -0.00513606\n",
            "  -0.00128514]\n",
            " [ 0.01901731  0.0074714  -0.00199188 ...  0.00104035 -0.00094115\n",
            "  -0.00346314]\n",
            " [ 0.00924615  0.00066728 -0.00143437 ... -0.00077465  0.00145904\n",
            "   0.00542418]\n",
            " ...\n",
            " [-0.00497739  0.00895168 -0.00813134 ...  0.01622392  0.00317553\n",
            "   0.00179347]\n",
            " [-0.01260489  0.00168561 -0.00311374 ...  0.00178937  0.01530977\n",
            "  -0.00710048]\n",
            " [-0.0053201   0.00613834 -0.00554961 ...  0.01022818  0.00538384\n",
            "   0.00643767]], shape=(100, 66), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#à chaque timestamp (caractère) on obtient la prédiction du prochain caractére\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "Yup-Ia7Tigm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy().decode('utf-8'))\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovOlJ5hnjOHy",
        "outputId": "e37e7c31-22a4-4252-ec3e-8422b480f125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " mes here?\n",
            "\n",
            "Second Citizen:\n",
            "Worthy Menenius Agrippa; one that hath always loved\n",
            "the people.\n",
            "\n",
            "First Ci\n",
            "\n",
            "Next Char Predictions:\n",
            " Au:lzcKjtyeLA' UMhTKRsW3HXG[UNK]xrbdwHB ?vnegNxigGbJQaV\n",
            "XpmoOTCrZ[UNK]PH cbUOOTE&'RIb-TDEUku!RFxbGDEzOco?bCh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#On passe à de l'apprentissage.\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y90l80-UjPoU",
        "outputId": "a90528a6-2218-41c3-cd0e-5d6405a13a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (32, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.190178, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS4TNrNQjsjj",
        "outputId": "21a2f0cb-7b0a-4582-c62b-f60d6a981221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.03454"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuration du modèle.\n",
        "model.compile(optimizer='adam', loss=loss,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "sAFnW5MAjwz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On peut enregistrer l'apprentissage de notre modèle en réalisant des checkpoints\n",
        "# Cela nous permettra de pouvoir résumer l'apprentissage à un temps voulu\n",
        "# Ou même de revenir en arriére.\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True,\n",
        "    verbose=1)"
      ],
      "metadata": {
        "id": "Ow1fq5j0j5o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=50, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF-1lgSgkOKC",
        "outputId": "3cf2c13f-15d4-4e52-98fe-ec4f00cc1fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 2.4025 - accuracy: 0.3398\n",
            "Epoch 1: saving model to ./training_checkpoints/ckpt_1\n",
            "345/345 [==============================] - 17s 39ms/step - loss: 2.4025 - accuracy: 0.3398\n",
            "Epoch 2/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 1.7904 - accuracy: 0.4724\n",
            "Epoch 2: saving model to ./training_checkpoints/ckpt_2\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 1.7903 - accuracy: 0.4724\n",
            "Epoch 3/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 1.5703 - accuracy: 0.5298\n",
            "Epoch 3: saving model to ./training_checkpoints/ckpt_3\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 1.5702 - accuracy: 0.5298\n",
            "Epoch 4/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 1.4452 - accuracy: 0.5623\n",
            "Epoch 4: saving model to ./training_checkpoints/ckpt_4\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 1.4453 - accuracy: 0.5623\n",
            "Epoch 5/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 1.3638 - accuracy: 0.5833\n",
            "Epoch 5: saving model to ./training_checkpoints/ckpt_5\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 1.3638 - accuracy: 0.5833\n",
            "Epoch 6/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 1.2995 - accuracy: 0.6000\n",
            "Epoch 6: saving model to ./training_checkpoints/ckpt_6\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 1.2995 - accuracy: 0.6000\n",
            "Epoch 7/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 1.2398 - accuracy: 0.6162\n",
            "Epoch 7: saving model to ./training_checkpoints/ckpt_7\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 1.2398 - accuracy: 0.6162\n",
            "Epoch 8/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 1.1788 - accuracy: 0.6333\n",
            "Epoch 8: saving model to ./training_checkpoints/ckpt_8\n",
            "345/345 [==============================] - 12s 36ms/step - loss: 1.1789 - accuracy: 0.6333\n",
            "Epoch 9/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 1.1132 - accuracy: 0.6529\n",
            "Epoch 9: saving model to ./training_checkpoints/ckpt_9\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 1.1132 - accuracy: 0.6529\n",
            "Epoch 10/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 1.0444 - accuracy: 0.6741\n",
            "Epoch 10: saving model to ./training_checkpoints/ckpt_10\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 1.0445 - accuracy: 0.6740\n",
            "Epoch 11/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.9815 - accuracy: 0.6936\n",
            "Epoch 11: saving model to ./training_checkpoints/ckpt_11\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 0.9815 - accuracy: 0.6936\n",
            "Epoch 12/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.9376 - accuracy: 0.7062\n",
            "Epoch 12: saving model to ./training_checkpoints/ckpt_12\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 0.9376 - accuracy: 0.7062\n",
            "Epoch 13/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.9220 - accuracy: 0.7088\n",
            "Epoch 13: saving model to ./training_checkpoints/ckpt_13\n",
            "345/345 [==============================] - 12s 36ms/step - loss: 0.9220 - accuracy: 0.7088\n",
            "Epoch 14/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.9129 - accuracy: 0.7100\n",
            "Epoch 14: saving model to ./training_checkpoints/ckpt_14\n",
            "345/345 [==============================] - 13s 36ms/step - loss: 0.9128 - accuracy: 0.7100\n",
            "Epoch 15/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.8900 - accuracy: 0.7161\n",
            "Epoch 15: saving model to ./training_checkpoints/ckpt_15\n",
            "345/345 [==============================] - 12s 36ms/step - loss: 0.8901 - accuracy: 0.7161\n",
            "Epoch 16/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8700 - accuracy: 0.7222\n",
            "Epoch 16: saving model to ./training_checkpoints/ckpt_16\n",
            "345/345 [==============================] - 13s 36ms/step - loss: 0.8700 - accuracy: 0.7222\n",
            "Epoch 17/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8548 - accuracy: 0.7262\n",
            "Epoch 17: saving model to ./training_checkpoints/ckpt_17\n",
            "345/345 [==============================] - 12s 36ms/step - loss: 0.8548 - accuracy: 0.7262\n",
            "Epoch 18/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.8499 - accuracy: 0.7265\n",
            "Epoch 18: saving model to ./training_checkpoints/ckpt_18\n",
            "345/345 [==============================] - 12s 36ms/step - loss: 0.8500 - accuracy: 0.7265\n",
            "Epoch 19/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8441 - accuracy: 0.7276\n",
            "Epoch 19: saving model to ./training_checkpoints/ckpt_19\n",
            "345/345 [==============================] - 12s 36ms/step - loss: 0.8441 - accuracy: 0.7276\n",
            "Epoch 20/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8412 - accuracy: 0.7277\n",
            "Epoch 20: saving model to ./training_checkpoints/ckpt_20\n",
            "345/345 [==============================] - 12s 36ms/step - loss: 0.8412 - accuracy: 0.7277\n",
            "Epoch 21/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8385 - accuracy: 0.7285\n",
            "Epoch 21: saving model to ./training_checkpoints/ckpt_21\n",
            "345/345 [==============================] - 12s 36ms/step - loss: 0.8385 - accuracy: 0.7285\n",
            "Epoch 22/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.8364 - accuracy: 0.7284\n",
            "Epoch 22: saving model to ./training_checkpoints/ckpt_22\n",
            "345/345 [==============================] - 12s 36ms/step - loss: 0.8364 - accuracy: 0.7284\n",
            "Epoch 23/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8355 - accuracy: 0.7282\n",
            "Epoch 23: saving model to ./training_checkpoints/ckpt_23\n",
            "345/345 [==============================] - 13s 37ms/step - loss: 0.8355 - accuracy: 0.7282\n",
            "Epoch 24/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8368 - accuracy: 0.7273\n",
            "Epoch 24: saving model to ./training_checkpoints/ckpt_24\n",
            "345/345 [==============================] - 12s 36ms/step - loss: 0.8368 - accuracy: 0.7273\n",
            "Epoch 25/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8375 - accuracy: 0.7271\n",
            "Epoch 25: saving model to ./training_checkpoints/ckpt_25\n",
            "345/345 [==============================] - 13s 36ms/step - loss: 0.8375 - accuracy: 0.7271\n",
            "Epoch 26/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8350 - accuracy: 0.7278\n",
            "Epoch 26: saving model to ./training_checkpoints/ckpt_26\n",
            "345/345 [==============================] - 13s 37ms/step - loss: 0.8350 - accuracy: 0.7278\n",
            "Epoch 27/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8375 - accuracy: 0.7268\n",
            "Epoch 27: saving model to ./training_checkpoints/ckpt_27\n",
            "345/345 [==============================] - 13s 37ms/step - loss: 0.8375 - accuracy: 0.7268\n",
            "Epoch 28/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8387 - accuracy: 0.7261\n",
            "Epoch 28: saving model to ./training_checkpoints/ckpt_28\n",
            "345/345 [==============================] - 12s 36ms/step - loss: 0.8387 - accuracy: 0.7261\n",
            "Epoch 29/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.8423 - accuracy: 0.7249\n",
            "Epoch 29: saving model to ./training_checkpoints/ckpt_29\n",
            "345/345 [==============================] - 13s 36ms/step - loss: 0.8425 - accuracy: 0.7248\n",
            "Epoch 30/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8427 - accuracy: 0.7244\n",
            "Epoch 30: saving model to ./training_checkpoints/ckpt_30\n",
            "345/345 [==============================] - 13s 37ms/step - loss: 0.8427 - accuracy: 0.7244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "  ## [0.0-1.0]\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    \n",
        "    # [0.0-66.0]\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "  # [0-66]\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "349xQgd1kQ0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "pTTziuNQpB47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "prompt = input('Veuilez entrer votre prompt ici : ')\n",
        "next_char = tf.constant([prompt])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(10000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print('_'*80 + '\\n\\n',result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6CXla-go7cs",
        "outputId": "c1314ba9-1145-43f0-d6b5-1711d999926c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thou hast more worthy tender years ungules\n",
            "As from my heart. This, bid how means,\n",
            "Thy seal and lord intent, yet in my word.\n",
            "Have I instruct his body through the wenches quarrell'd brother\n",
            "Are thine and what often revenges from the head to beg\n",
            "which quinks forsworn; ready as from me:\n",
            "I have it in the inianact.\n",
            "\n",
            "LADY GREMINA:\n",
            "A sha-wate reing a victory!\n",
            "\n",
            "BRUTUS:\n",
            "Set down\n",
            "It is a but a robbly daughter,\n",
            "After all these woes hath been\n",
            "dreams, his fand, honour, thou chudged\n",
            "Which way the widdemies of your lambs,\n",
            "I'll find shimb, Master driving it ever suck\n",
            "Writes, under an hungry clouds,\n",
            "But tarry and from thee to a wenthware:\n",
            "Why, how the world between two suitors,\n",
            "And downright hang Henryonth and\n",
            "what off without coming as a hope--what wench,\n",
            "Whose stingwicK I lungs upon your infant.\n",
            "\n",
            "GRUMIO:\n",
            "I confess the swome said, and so it is:\n",
            "A sister\n",
            "Her in his master, or it, may Inloralt\n",
            "aboat that meant to bear it thee.\n",
            "\n",
            "PETRUCHIO:\n",
            "I should die without there.\n",
            "\n",
            "FRANTONIO:\n",
            "Look you not so.\n",
            "\n",
            "KATHARINA:\n",
            "I am of your wife.\n",
            "\n",
            "GREMIO:\n",
            "Ah, if I see, to proved\n",
            "O Citus.\n",
            "\n",
            "COMINIUS:\n",
            "What.\n",
            "\n",
            "VIRGIHA:\n",
            "What if it may be worse than she: 'I'll wip weep.\n",
            "\n",
            "ANTIGONUS:\n",
            "Linen most word.\n",
            "Nichorse it in the devil thing,\n",
            "And every thing did Rot an Lord:\n",
            "Servant, for a husband; and, thou hast won.\n",
            "\n",
            "PETRUCHIO:\n",
            "Come on, sir; here, sir.\n",
            "\n",
            "PROSPERO:\n",
            "By zeal, patience!\n",
            "Now it holds upon us! was dead.\n",
            "\n",
            "LUCENTIO:\n",
            "I know the Petir; if you think to old Minio\n",
            "Courany, and I take him grieved: now in thy loyace of\n",
            "jest: wherefore? when messenger?\n",
            "\n",
            "BIONDELLO:\n",
            "\n",
            "Third Citizen:\n",
            "Admity, my father!\n",
            "\n",
            "CLARENCE:\n",
            "Between you word; I peace.\n",
            "\n",
            "BIONDELLO:\n",
            "Yes; I would fear the death of all.\n",
            "\n",
            "PROSPERO:\n",
            "Who's inknows?\n",
            "\n",
            "TRUNIO:\n",
            "For I beg it Peterm good.\n",
            "\n",
            "GRUMIO:\n",
            "I say his name is Landard-tion; diest thou the mean?\n",
            "\n",
            "HORTENSIO:\n",
            "Faith on him, which is here changed intent?\n",
            "'Tis Aumars. What, have we will not done so?\n",
            "But are welcome? All the sun setrise.\n",
            "\n",
            "VINCENTIO:\n",
            "First Without: thou know'st, we do tell the people,\n",
            "A nurthe abode, but the very windows send\n",
            "her throne that never means to thee 'Deak me.\n",
            "\n",
            "HORTENSIO:\n",
            "'Tis not your will.\n",
            "\n",
            "BIONDELLO:\n",
            "I play thee: come, you have been:\n",
            "a bawn, for a thousand! weD:\n",
            "Therefore picious tongue!\n",
            "And ifful marriag war! I am out of the morn\n",
            "against my head and beaten. Come, endow my art:\n",
            "Acquainted bring them over with me.\n",
            "\n",
            "PROSPERO:\n",
            "Sir, they believe no sixture.\n",
            "\n",
            "GRUMIO:\n",
            "Then show him nothing me; let it do wefe?\n",
            "\n",
            "GRUMIO:\n",
            "Call forth an oath besie: everour yourself\n",
            "And thereby I meet to heart. But now\n",
            "I fear? show her thanks and so for his thrift;\n",
            "And title in your wife, they are wronged in\n",
            "Prebentio, and most patientle at the fore\n",
            "Was emb, gentleman in my duty.\n",
            "\n",
            "Wreptiot LUCIO:\n",
            "\n",
            "KATHARINA:\n",
            "And I am sorry for his subfrit;\n",
            "If, it is, sir; he must curp her, as I seeming\n",
            "Waste of fear thy sister's song.\n",
            "But, hearing the hearing of the penscaponors.\n",
            "How? will lastly leann thee, thou shame? o'erleck'd.\n",
            "\n",
            "BRUTUS:\n",
            "I am afford.\n",
            "\n",
            "KATHARINA:\n",
            "Ye stand his through lord-scandal points,\n",
            "And bear the indition of the people, may\n",
            "The tidings of this fight again:\n",
            "The sweet rib will him.\n",
            "\n",
            "KATHARINA:\n",
            "I never did cheerly so.\n",
            "\n",
            "PROSPERO:\n",
            "Hear sie not, God shine hurous;\n",
            "For weirs, we will. find, wearons!\n",
            "By, widow Dimmonded, is an honest end\n",
            "hath liming lardune.\n",
            "\n",
            "HORTENSIO:\n",
            "And heaven and your good reason?\n",
            "\n",
            "SCYRINI:\n",
            "Ansel both-weaking.\n",
            "\n",
            "Pedant:\n",
            "Will go,\n",
            "On 'twas on to pieces two Froven pies?\n",
            "\n",
            "GRUMIO:\n",
            "The worst of these lends are like the Servince:\n",
            "He is alive.'\n",
            "\n",
            "KATHARINA:\n",
            "Life One occasion; then let the wanton but\n",
            "a hopse of his youth, a qualet by like and eat.\n",
            "\n",
            "SEBASTYAN:\n",
            "LAther?\n",
            "\n",
            "First Lord:\n",
            "Beauth't will not, bear your presence?\n",
            "\n",
            "PETRUCHIO:\n",
            "When you are all the head, the world as it was to hear?\n",
            "\n",
            "TRANIO:\n",
            "Then go with me to more.\n",
            "\n",
            "KATHARINA:\n",
            "Pity;\n",
            "Go think I hear not one.\n",
            "\n",
            "LUCENTIO:\n",
            "And I am now will not him.\n",
            "\n",
            "KATHARINA:\n",
            "They come, since! O throuble Minorator,\n",
            "Tagers or being althouge one joy and weak.\n",
            "\n",
            "GRUMIO:\n",
            "Why, sir, welcome home.\n",
            "\n",
            "GRUMIO:\n",
            "Call hither.\n",
            "\n",
            "MIRANDA:\n",
            "O, brother, didst thou be?\n",
            "When? Of all the city?\n",
            "\n",
            "BIONDELLO:\n",
            "Or else you woo contrary way this\n",
            "Aught I have set a day, a brief.\n",
            "\n",
            "LUCENTIO:\n",
            "I mean, sir. Where's a knife is, and yet to thee write:\n",
            "And bring you bearing me, faith, I will not pity;\n",
            "In thought o'er-run his horse confess, we shall\n",
            "encounter with thee: over ease implored\n",
            "Her noble son.\n",
            "\n",
            "ARIEL:\n",
            "Millied,\n",
            "Thou art my sister: sure, the steen\n",
            "and a hare but swift Hearted without\n",
            "considered. The most chower,\n",
            "if thou lies' the stafful sister's of his hate,\n",
            "And in her beauty doth call thee bawd:\n",
            "This disgrosses hath been down to us!\n",
            "\n",
            "BISTRSTA:\n",
            "and your wife,\n",
            "Behold King Henry of Vinnemies,\n",
            "Will Itable fine evid, cannot see the moon\n",
            "how to beat ope them, these two days show me mischief:\n",
            "'Tis lest knock thus will not greated\n",
            "And soor my fair civil and bridegroom!\n",
            "\n",
            "offician:\n",
            "What hast we may weap and soldly liege!\n",
            "\n",
            "KATHARINA:\n",
            "I know it best is nothing sime more greater pinied.\n",
            "\n",
            "HORTENSIO:\n",
            "\n",
            "PROSPERO:\n",
            "I'll privilly among you.\n",
            "\n",
            "PROSPERO:\n",
            "At honesty.\n",
            "\n",
            "ANGELO:\n",
            "That you see, or thou shalt crow born.\n",
            "The maid I might, thus wanting: your\n",
            "fair way within, sir, sir.\n",
            "\n",
            "PROSPERO:\n",
            "The more I saw again? ride it good heaven!\n",
            "What will the other moan? she thus deserved within the king.\n",
            "\n",
            "GRUMIO:\n",
            "I shall bring me to the head.\n",
            "O me,\n",
            "My drifty Clifal, than was thy lord, I am\n",
            "I not-garden, I will not do it.\n",
            "\n",
            "GRUMIO:\n",
            "Then is the marriage of the torthy\n",
            "To fate, and heart from thence.\n",
            "\n",
            "ISABELLA:\n",
            "O, peace! thou art thyself and the vigaretes\n",
            "Here on the intents do concluse your eye\n",
            "Might in the foxery day, each one: thy world\n",
            "Lucentio in everyonly\n",
            "Upon a time: bound to like a thifty know\n",
            "Thus do I now. Then Prithee, cry against his body\n",
            "As yourself to wait an end.\n",
            "\n",
            "BIANCA:\n",
            "What thinker thou stopp'd, in the sore, my moyer keason Tybalt's.\n",
            "\n",
            "GRUMIO:\n",
            "What in my danger, stay with it which say these woods?\n",
            "What we take up untherefore, good Gaunt; and soul the devil\n",
            "Was brother--\n",
            "Vincentio.\n",
            "\n",
            "BIONDELLO:\n",
            "See, lut live his broishes to her.\n",
            "\n",
            "PROSPERO:\n",
            "My friend!\n",
            "A crewling woranny!\n",
            "\n",
            "KATHARINA:\n",
            "I do, and fear to thee.\n",
            "\n",
            "Keezer,\n",
            "I would thou think I should refuse thee.\n",
            "\n",
            "PETRUCHIO:\n",
            "A'stance of him.\n",
            "\n",
            "ANIEL:\n",
            "Yes, I convey'd her; has you tappidy!\n",
            "Warwick thus whither.\n",
            "\n",
            "Pedant:\n",
            "O Prinnight!\n",
            "\n",
            "BRUTUS:\n",
            "Merity!\n",
            "\n",
            "MENENIUS:\n",
            "What if wrong's too faced so bridegrow heard\n",
            "When in the gots Pash on the draber! Vouchsafe, my lord,\n",
            "Weil, once geofilt only fortune's mistress.\n",
            "\n",
            "LUCENTIO:\n",
            "I mean on thee.\n",
            "\n",
            "FRATHRY:\n",
            "He is a sister? because I am a gentleman:\n",
            "Therefore presently, or poison are toward.\n",
            "\n",
            "Lovent\n",
            "And free to beauty Please.\n",
            "\n",
            "BIONDELLO:\n",
            "Nay, then.\n",
            "\n",
            "MARCIUS:\n",
            "Fear be thou.\n",
            "\n",
            "HORTENSIO:\n",
            "Your tribunes knows he.\n",
            "Helm!\n",
            "\n",
            "GRUCULIA:\n",
            "Yet awake, letters your father's son.\n",
            "And title in spirit there, beside\n",
            "Saying the farthest of all, against the worst\n",
            "And blunted for swift house, fools, how fare, spake hinher\n",
            "Boldly and fellows and reversigh,\n",
            "And in the ministers attend on thee:\n",
            "I know her all, the rest!\n",
            "\n",
            "TLBO:\n",
            "I do not think thou hast bare to.\n",
            "Welcome, sir, here.\n",
            "\n",
            "PETRUCHIO:\n",
            "What, you are hearing on forth, well, in the purpose. I go to peace!\n",
            "\n",
            "BRUTUS:\n",
            "I am groad of all.\n",
            "Here's musu may be shook no portance.\n",
            "\n",
            "ANTONIO:\n",
            "The very isle, he doth:\n",
            "here, sir; here, she is not this and but thine and breath;\n",
            "And, if thou fardelovet of Peterple and maintain it is nothing;\n",
            "So being a thorsuares unknown to the Master\n",
            "Erried about him with thee then all the world's uncles\n",
            "How he may soft so soon feeling to bed,\n",
            "We know your daughter, come, unwoxt 'dalk, gaunt and\n",
            "Your birthrig's. I\n",
            "am command entertain your hand;\n",
            "And therefore I have foundation as\n",
            "a hank and feeling in their cubond:\n",
            "They hou levil and her implarter patricians, I\n",
            "House--would I wish dew?\n",
            "Send what you mest ignoow,\n",
            "Who is indeed? Take it not his wife take.\n",
            "\n",
            "GRUMIO:\n",
            "I say then Bushy. Martina,\n",
            "And in the warrick in fortunes took,\n",
            "That you, my master. We are forgot\n",
            "his admired down.\n",
            "\n",
            "BONANCEMIO:\n",
            "And here comes age boss!\n",
            "\n",
            "Third Lice:\n",
            "Ward you gone, and thus blood and bear her dowry.\n",
            "\n",
            "GRUMIO:\n",
            "I would thou gave him so: let's wan the warrants fine arms.\n",
            "\n",
            "VOLUMNIA:\n",
            "And you shall have not.\n",
            "\n",
            "TRANIO:\n",
            "Sir, away, are they have.\n",
            "\n",
            "PETRUCHIO:\n",
            "Who knows not that?\n",
            "\n",
            "GONZALO:\n",
            "Fie, fire! What think you of\n",
            "her?\n",
            "\n",
            "BIONTELLO:\n",
            "Peter.\n",
            "\n",
            "LUCENTIO:\n",
            "Here is thou speak'st true; 'Hit honoted: then, fooling use thee boast\n",
            "While seem to the burthent of a woman,\n",
            "how mine advocked lives unto me:\n",
            "I contend thee now so surtly there;\n",
            "And therefore look upon the time and beat under\n",
            "Against our house the benefit his queen and shore;\n",
            "And with usurpers grey, eather than your eye\n",
            "Becomes a mistrest guess.\n",
            "\n",
            "KATHARINA:\n",
            "I'll all hope so tale: marry, hie you to depose,\n",
            "sir, his noble sir, she weeps, they say, thinks he\n",
            "knfell that joy and forward.\n",
            "\n",
            "PETRUCHIO:\n",
            "Between the gates.\n",
            "\n",
            "SIANA:\n",
            "O Kater! what's the mean?\n",
            "Have your honour that set down,\n",
            "On poir more, no beast swrange them that they have none ended how thou wast now meaning\n",
            "To be set down the midning love; or the\n",
            "eye blows with what chosels, but he'll do't,\n",
            "Coosen thou did promise on thee, to our triumph of mother!\n",
            "I assure it, O you please.\n",
            "\n",
            "GREMIO:\n",
            "I pray now, deaf for Claugio,\n",
            "To buy for her,\n",
            "O heart, sir! now may swear it!\n",
            "\n",
            "TRANIO:\n",
            "Call them for thee.\n",
            "\n",
            "First Servant:\n",
            "With one please the game of Cambrow.\n",
            "\n",
            "VOLUMNIA:\n",
            "But my thundlessil arms,\n",
            "My sorrows I possible Signior law:\n",
            "Among without assurance well!\n",
            "Think strangers, and though before your hands and\n",
            "where in my eyes and names-stood,\n",
            "When I have heard of combands I'll rig\n",
            "Name-ballads of thy neck, how doth man's\n",
            "Have thee DUKE VINCENTIO:\n",
            "This is thought on thee; thou haster, or else you embroy.\n",
            "\n",
            "BIONDELLO:\n",
            "O, I swear,\n",
            "If you VIGodd--what had burn born:\n",
            "Are not so doing a banish well: thou stitest stealing thum, I will;\n",
            "For, I presently expedient too,\n",
            "If ever he remeds, whiles the reason of his way?\n",
            "On Thomas, I'ld warrant me.\n",
            "\n",
            "GRUMIO:\n",
            "I thought of woe derived.\n",
            "\n",
            "BIPOND:\n",
            "Let's me die for him. He, please you,\n",
            "My master, bid your sin so on her\n",
            "Advock'd her applauding in thee.\n",
            "\n",
            "First God:\n",
            "Thou hast not show myself and fest, \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 27.482417106628418\n"
          ]
        }
      ]
    }
  ]
}